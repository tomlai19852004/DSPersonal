https://medium.com/@genekogan/machine-learning-for-artists-e93d20fdb097?source=---
Excerpt from A Book from the Sky, Dec 2015Machines start to dreamLike many, I’ve been excited by the rise of Deep Learning, a branch of ML which has recently achieved state-of-the-art results for a variety of standard tasks, and has shown a penchant for encoding representations of large, disorganized, unlabeled data like raw images, video, audio, and text. Artistic hacks of deep learning software rapidly emerged in 2015, and I participated by producing a number of new works.Why is a Raven Like a Writing Desk? Stylenet + Alice in Wonderland, Sep 2015The most recent, excerpted above, was “A Book from the Sky”, in which I fed a large database of handwritten Chinese characters to a neural network which learned a generative representation of them, enabling it to “fantasize” fake samples of real characters, and render smooth interpolations among groups of complimentary characters. In September, I made “Why is a Raven Like a Writing Desk?”, which applied the style transfer or “stylenet” technique to a scene in Alice in Wonderland, as part of a series of animations.Both were shared by Yann LeCun [1][2], among others in the deep learning research community. My hope is that such public works motivate more researchers to release their software in an accessible way for people outside of academic research to spin off new projects.I wrote about this phenomenon of deep learning artistic research in a medium post last month.From Pixels to ParagraphsHow artistic experiments with deep learning guard us from hypemedium.comTo learn shallow learning deeply or learn deep learning shallowly?SVM FTWDeep learning poses some pedagogical challenges. First, the prerequisite software can be difficult to install, characterized by numerous and sometimes obscure dependencies, unpredictable runtime errors, and instructions targeted towards people assumed to have a background in computer science or software engineering. For those without one, debugging can be very time-consuming if it can’t be taken care of in advance, and distracts from the main educational objectives.Additionally, the software contains few of the high-level abstractions found in creative coding libraries. The algorithms are expertly hand-crafted to effectively do one narrowly-defined task, and do it very well. Thus, it can be difficult to apply the software creatively in ways that are much different from how the original authors already demonstrated them. Furthermore, the computational expensiveness of most deep neural networks makes virtually all real-time applications impossible. A lack of desirable and large enough datasets, memory restrictions, and various other complications reduce it further.For those reasons, I don’t think it makes sense yet to structure an ML course for artists around the new deep learning libraries. It would be more effective to use more mature and stable tools to demonstrate applications of classification, regression, and clustering. For real-time and performance-based purposes, Wekinator is excellent for this, encapsulating most of the gritty details of ML and providing a convenient interface via open sound control (OSC), letting artists and musicians plug in their favorite tools and observe the essential functions of ML routines from a high-level perspective. For non-real-time tasks like data visualization and inference, scikit-learn is the consensus choice for its ease-of-use, documentation, and accompanying examples.I am optimistic deep learning will become more practical to teach soon, perhaps even before the end of 2016. By then, students who have thoroughly studied “classical” machine learning will be much more prepared to dive into the deep end.